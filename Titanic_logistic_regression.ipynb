{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1vM0a_FkRwh"
      },
      "source": [
        "# Logistic Regression "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wsuQJKAkRwq",
        "outputId": "60708421-46aa-49ea-b45e-7a7c45a2effd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 50 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 56.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=66d3da3c2d61de52b36cde630119c3bbb05516e17b8a8d1e2df83f22dd095299\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "7NKqk-PAkRws"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName('myproj').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "UvqboNkXkRwt"
      },
      "outputs": [],
      "source": [
        "data = spark.read.csv('titanic.csv',inferSchema=True,header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAnGfr3UkRwu",
        "outputId": "8a41a86a-e092-4336-810d-f6c7400952f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- PassengerId: integer (nullable = true)\n",
            " |-- Survived: integer (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZVQtRumk2Lq",
        "outputId": "f07ebe3b-c20b-4604-b3fb-c6fa67f4b555"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k19o4mfNkRww",
        "outputId": "19196240-9464-4ae2-90b6-87f6da676915"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PassengerId',\n",
              " 'Survived',\n",
              " 'Pclass',\n",
              " 'Name',\n",
              " 'Sex',\n",
              " 'Age',\n",
              " 'SibSp',\n",
              " 'Parch',\n",
              " 'Ticket',\n",
              " 'Fare',\n",
              " 'Cabin',\n",
              " 'Embarked']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "w1nkLVjgkRwx"
      },
      "outputs": [],
      "source": [
        "my_cols = data.select(['Survived',\n",
        " 'Pclass',\n",
        " 'Sex',\n",
        " 'Age',\n",
        " 'SibSp',\n",
        " 'Parch',\n",
        " 'Fare',\n",
        " 'Embarked'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KBnQygeTkRwz"
      },
      "outputs": [],
      "source": [
        "my_final_data = my_cols.na.drop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn2HsFFQkRw0"
      },
      "source": [
        "#### Working with Categorical Columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "pxKKR7VqkRw1"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,OneHotEncoder,StringIndexer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "_-yHuofkkRw2"
      },
      "outputs": [],
      "source": [
        "gender_indexer = StringIndexer(inputCol='Sex',outputCol='SexIndex')\n",
        "gender_encoder = OneHotEncoder(inputCol='SexIndex',outputCol='SexVec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "a5gkjpukkRw2"
      },
      "outputs": [],
      "source": [
        "embark_indexer = StringIndexer(inputCol='Embarked',outputCol='EmbarkIndex')\n",
        "embark_encoder = OneHotEncoder(inputCol='EmbarkIndex',outputCol='EmbarkVec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "WMjJ_GKFkRw3"
      },
      "outputs": [],
      "source": [
        "assembler = VectorAssembler(inputCols=['Pclass',\n",
        " 'SexVec',\n",
        " 'Age',\n",
        " 'SibSp',\n",
        " 'Parch',\n",
        " 'Fare',\n",
        " 'EmbarkVec'],outputCol='features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "l1czIHJ2kRw4"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuRaAhZnkRw4"
      },
      "source": [
        "## Pipelines \n",
        "\n",
        "In machine learning, it is common to run a sequence of algorithms to process and learn from data. \n",
        "\n",
        "MLlib represents such a workflow as a Pipeline, which consists of a sequence of PipelineStages (Transformers and Estimators) to be run in a specific order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "UKk4412ZkRw5"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "v0D_880okRw5"
      },
      "outputs": [],
      "source": [
        "log_reg_titanic = LogisticRegression(featuresCol='features',labelCol='Survived')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "id": "5GZtMBJ7kRw6"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(stages=[gender_indexer,embark_indexer,\n",
        "                           gender_encoder,embark_encoder,\n",
        "                           assembler,log_reg_titanic])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "id": "9ct_vJlVkRw6"
      },
      "outputs": [],
      "source": [
        "train_titanic_data, test_titanic_data = my_final_data.randomSplit([0.7,.3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "id": "LxkRN-oGkRw7"
      },
      "outputs": [],
      "source": [
        "fit_model = pipeline.fit(train_titanic_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": true,
        "id": "_JyKWCQ6kRw7"
      },
      "outputs": [],
      "source": [
        "results = fit_model.transform(test_titanic_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "id": "51TPQVyHkRw8"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "id": "EtWLcKbNkRw8"
      },
      "outputs": [],
      "source": [
        "my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
        "                                       labelCol='Survived')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axLOxQugkRw9",
        "outputId": "ed0a14ec-eee1-420a-a89f-d4c202fa1c2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+\n",
            "|Survived|prediction|\n",
            "+--------+----------+\n",
            "|       0|       1.0|\n",
            "|       0|       1.0|\n",
            "|       0|       1.0|\n",
            "|       0|       1.0|\n",
            "|       0|       1.0|\n",
            "|       0|       1.0|\n",
            "|       0|       1.0|\n",
            "|       0|       1.0|\n",
            "|       0|       1.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results.select('Survived','prediction').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "id": "0YrkRD_rkRw9"
      },
      "outputs": [],
      "source": [
        "AUC = my_eval.evaluate(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfsOdh0kkRw9",
        "outputId": "7e8f1c90-e050-439f-8069-b33712fa962f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7733202870189172"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "AUC"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [conda root]",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}